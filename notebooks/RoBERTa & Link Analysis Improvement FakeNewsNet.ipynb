{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "876155a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch\n",
    "from transformers import RobertaModel, RobertaTokenizer\n",
    "import tldextract\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import torch.nn as nn\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "from tqdm import tqdm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d09e2004",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 1: Load and Prepare Data\n",
    "fake_news = pd.read_csv('data/fake.csv')  # Replace with the correct path\n",
    "real_news = pd.read_csv('data/real.csv')  # Replace with the correct path\n",
    "\n",
    "fake_news = fake_news.drop(columns=['id'], errors='ignore')\n",
    "real_news = real_news.drop(columns=['id'], errors='ignore')\n",
    "fake_news['labels'] = 1\n",
    "real_news['labels'] = 0\n",
    "\n",
    "data = pd.concat([fake_news[['title', 'labels', 'news_url']], real_news[['title', 'labels', 'news_url']]], ignore_index=True)\n",
    "data.dropna(subset=['title'], inplace=True)\n",
    "\n",
    "# Step 2: Refined Data Augmentation\n",
    "def augment_title(title):\n",
    "    synonyms = {'fake': 'false', 'news': 'story'}\n",
    "    words = title.split()\n",
    "    return ' '.join([synonyms.get(w.lower(), w) for w in words])\n",
    "\n",
    "data['title'] = data['title'].apply(augment_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8ea9ad1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 3: Extract URL features\n",
    "def extract_url_features(url):\n",
    "    if isinstance(url, float):\n",
    "        url = str(url)\n",
    "    ext = tldextract.extract(url)\n",
    "    return {\n",
    "        'domain': ext.domain,\n",
    "        'subdomain': ext.subdomain,\n",
    "        'url_length': len(url),\n",
    "        'has_query': 1 if '?' in url else 0,\n",
    "        'has_hyphens': 1 if '-' in url else 0,\n",
    "        'has_numbers': 1 if any(c.isdigit() for c in url) else 0,\n",
    "    }\n",
    "\n",
    "url_features = data['news_url'].apply(extract_url_features)\n",
    "url_features_df = pd.DataFrame(url_features.tolist())\n",
    "\n",
    "# Encode and normalize URL features\n",
    "url_features_encoded = pd.get_dummies(url_features_df, columns=['domain', 'subdomain'])\n",
    "scaler = StandardScaler()\n",
    "url_features_encoded = pd.DataFrame(scaler.fit_transform(url_features_encoded), columns=url_features_encoded.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c963ebf4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jun_k\\anaconda3\\lib\\site-packages\\sklearn\\base.py:474: FutureWarning: `BaseEstimator._validate_data` is deprecated in 1.6 and will be removed in 1.7. Use `sklearn.utils.validation.validate_data` instead. This function becomes public and is part of the scikit-learn developer API.\n",
      "  warnings.warn(\n",
      "C:\\Users\\jun_k\\anaconda3\\lib\\site-packages\\sklearn\\utils\\_tags.py:354: FutureWarning: The SMOTE or classes from which it inherits use `_get_tags` and `_more_tags`. Please define the `__sklearn_tags__` method, or inherit from `sklearn.base.BaseEstimator` and/or other appropriate mixins such as `sklearn.base.TransformerMixin`, `sklearn.base.ClassifierMixin`, `sklearn.base.RegressorMixin`, and `sklearn.base.OutlierMixin`. From scikit-learn 1.7, not defining `__sklearn_tags__` will raise an error.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Step 4: Vectorize Titles\n",
    "vectorizer = CountVectorizer(max_features=5000)  # Limit features to avoid memory issues\n",
    "title_features_vectorized = vectorizer.fit_transform(data['title']).toarray()\n",
    "\n",
    "# Step 5: Align Data\n",
    "min_length = min(len(title_features_vectorized), len(url_features_encoded))\n",
    "title_features_vectorized = title_features_vectorized[:min_length]\n",
    "url_features_encoded = url_features_encoded.iloc[:min_length]\n",
    "data = data.iloc[:min_length]\n",
    "\n",
    "# Step 6: Combine Features for SMOTE\n",
    "combined_features = np.hstack([title_features_vectorized, url_features_encoded])\n",
    "\n",
    "# Apply SMOTE\n",
    "smote = SMOTE(random_state=42)\n",
    "combined_features_resampled, labels_resampled = smote.fit_resample(combined_features, data['labels'])\n",
    "\n",
    "# Step 7: Split Combined Features Back\n",
    "title_features_resampled = combined_features_resampled[:, :title_features_vectorized.shape[1]]\n",
    "url_features_resampled = combined_features_resampled[:, title_features_vectorized.shape[1]:]\n",
    "\n",
    "# Convert resampled title features back to text\n",
    "title_features_resampled = [\n",
    "    \" \".join(vectorizer.inverse_transform(title_row.reshape(1, -1))[0]) for title_row in title_features_resampled\n",
    "]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "21eee3e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data preparation complete.\n"
     ]
    }
   ],
   "source": [
    "# Tokenizer initialization\n",
    "tokenizer = RobertaTokenizer.from_pretrained('roberta-base')\n",
    "\n",
    "# Step 8: Split Data into Train/Test Sets\n",
    "train_texts, test_texts, train_labels, test_labels, train_urls, test_urls = train_test_split(\n",
    "    title_features_resampled, labels_resampled, url_features_resampled, test_size=0.2, random_state=42\n",
    ")\n",
    "print(\"Data preparation complete.\")\n",
    "\n",
    "# Tokenize the train and test texts\n",
    "train_encodings = tokenizer(train_texts, truncation=True, padding=True, max_length=512)\n",
    "test_encodings = tokenizer(test_texts, truncation=True, padding=True, max_length=512)\n",
    "\n",
    "# Convert to torch tensors\n",
    "train_encodings = {key: torch.tensor(val) for key, val in train_encodings.items()}\n",
    "test_encodings = {key: torch.tensor(val) for key, val in test_encodings.items()}\n",
    "\n",
    "class CombinedDataset(Dataset):\n",
    "    def __init__(self, encodings, labels, url_features):\n",
    "        self.encodings = encodings\n",
    "        self.labels = labels\n",
    "        self.url_features = torch.tensor(url_features, dtype=torch.float)\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        item = {key: val[idx] for key, val in self.encodings.items()}\n",
    "        item['labels'] = torch.tensor(self.labels.iloc[idx], dtype=torch.long)\n",
    "        item['url_features'] = self.url_features[idx]\n",
    "        return item\n",
    "\n",
    "# Create datasets\n",
    "train_dataset = CombinedDataset(train_encodings, train_labels, train_urls)\n",
    "test_dataset = CombinedDataset(test_encodings, test_labels, test_urls)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "eval_dataloader = DataLoader(test_dataset, batch_size=16)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "13deca3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of RobertaModel were not initialized from the model checkpoint at roberta-base and are newly initialized: ['roberta.pooler.dense.bias', 'roberta.pooler.dense.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "# Model with enhanced URL features\n",
    "class RobertaWithEnhancedURLClassifier(nn.Module):\n",
    "    def __init__(self, roberta_model_name, url_feature_dim):\n",
    "        super(RobertaWithEnhancedURLClassifier, self).__init__()\n",
    "        self.roberta = RobertaModel.from_pretrained(roberta_model_name)\n",
    "        self.url_transform = nn.Sequential(\n",
    "            nn.Linear(url_feature_dim, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64)\n",
    "        )\n",
    "        self.classifier = nn.Linear(self.roberta.config.hidden_size + 64, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, url_features):\n",
    "        roberta_output = self.roberta(input_ids=input_ids, attention_mask=attention_mask).pooler_output\n",
    "        url_transformed = self.url_transform(url_features)\n",
    "        combined_input = torch.cat((roberta_output, url_transformed), dim=1)\n",
    "        logits = self.classifier(combined_input)\n",
    "        return logits\n",
    "\n",
    "url_feature_dim = train_urls.shape[1]\n",
    "model = RobertaWithEnhancedURLClassifier('roberta-base', url_feature_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c534010c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model training function\n",
    "def train_model(model, train_dataloader, eval_dataloader, num_epochs, device):\n",
    "    optimizer = AdamW(model.parameters(), lr=1e-5)\n",
    "    num_training_steps = num_epochs * len(train_dataloader)\n",
    "    lr_scheduler = get_scheduler(\"linear\", optimizer=optimizer, num_warmup_steps=0, num_training_steps=num_training_steps)\n",
    "\n",
    "    model.to(device)\n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(\n",
    "                input_ids=batch[\"input_ids\"],\n",
    "                attention_mask=batch[\"attention_mask\"],\n",
    "                url_features=batch[\"url_features\"]\n",
    "            )\n",
    "            logits = outputs\n",
    "            loss_fct = nn.CrossEntropyLoss(weight=torch.tensor([1.0, 1.5], device=device))\n",
    "            loss = loss_fct(logits, batch[\"labels\"])\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        model.eval()\n",
    "        eval_loss = 0\n",
    "        for batch in eval_dataloader:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(\n",
    "                    input_ids=batch[\"input_ids\"],\n",
    "                    attention_mask=batch[\"attention_mask\"],\n",
    "                    url_features=batch[\"url_features\"]\n",
    "                )\n",
    "                logits = outputs\n",
    "                loss = loss_fct(logits, batch[\"labels\"])\n",
    "                eval_loss += loss.item()\n",
    "        print(f\"Epoch {epoch + 1}/{num_epochs}, Evaluation Loss: {eval_loss / len(eval_dataloader)}\")\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "8f338aea",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██████████████▊                                                           | 1745/8725 [2:36:09<7:54:03,  4.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5, Evaluation Loss: 0.3266925105582113\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|█████████████████████████████▌                                            | 3490/8725 [5:20:54<5:41:48,  3.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/5, Evaluation Loss: 0.33431279974684835\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|████████████████████████████████████████████▍                             | 5235/8725 [8:06:11<3:48:25,  3.93s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/5, Evaluation Loss: 0.3136727886756102\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|██████████████████████████████████████████████████████████▍              | 6980/8725 [10:52:08<2:00:08,  4.13s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5, Evaluation Loss: 0.2904902120596075\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████| 8725/8725 [13:48:25<00:00,  5.70s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/5, Evaluation Loss: 0.3022398519419236\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as fake_news_model_roberta_fakenewsnet.pth\n"
     ]
    }
   ],
   "source": [
    "# Train Model\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\n",
    "num_epochs = 5\n",
    "model = train_model(model, train_dataloader, eval_dataloader, num_epochs, device)\n",
    "\n",
    "# Save the trained model\n",
    "torch.save({\n",
    "    'model_state_dict': model.state_dict(),\n",
    "}, \"fake_news_model_roberta_fakenewsnet.pth\")\n",
    "print(\"Model saved as fake_news_model_roberta_fakenewsnet.pth\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "174c4a58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.8823276479862405\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.90      0.86      0.88      3471\n",
      "        Fake       0.87      0.90      0.88      3506\n",
      "\n",
      "    accuracy                           0.88      6977\n",
      "   macro avg       0.88      0.88      0.88      6977\n",
      "weighted avg       0.88      0.88      0.88      6977\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay, accuracy_score, classification_report\n",
    "import numpy as np\n",
    "\n",
    "# Evaluation\n",
    "model.eval()\n",
    "predictions = []\n",
    "true_labels = []\n",
    "\n",
    "for batch in eval_dataloader:\n",
    "    batch = {k: v.to(device) for k, v in batch.items()}\n",
    "    with torch.no_grad():\n",
    "        outputs = model(\n",
    "            input_ids=batch[\"input_ids\"],\n",
    "            attention_mask=batch[\"attention_mask\"],\n",
    "            url_features=batch[\"url_features\"]\n",
    "        )\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        predictions.extend(preds.cpu().numpy())\n",
    "        true_labels.extend(batch[\"labels\"].cpu().numpy())\n",
    "\n",
    "# Save predictions and true labels (optional)\n",
    "np.save(\"predictions_roberta_fakenewsnet.npy\", predictions)\n",
    "np.save(\"true_labels_roberta_fakenewsnet.npy\", true_labels)\n",
    "\n",
    "\n",
    "# Evaluation Metrics\n",
    "conf_matrix = confusion_matrix(true_labels, predictions, labels=[0, 1])\n",
    "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=['Real', 'Fake'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()\n",
    "\n",
    "print(\"Accuracy:\", accuracy_score(true_labels, predictions))\n",
    "print(classification_report(true_labels, predictions, target_names=['Real', 'Fake']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aaf6ec3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
