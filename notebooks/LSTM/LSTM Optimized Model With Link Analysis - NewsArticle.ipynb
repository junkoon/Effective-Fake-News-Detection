{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "88f09669",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, ConfusionMatrixDisplay\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de8c9183",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Load and Preprocess Data ==========\n",
    "news_data = pd.read_csv('data/news_articles.csv')\n",
    "\n",
    "# Keep only relevant columns\n",
    "news_data = news_data.drop(columns=['author', 'published', 'text', 'language', 'main_img_url', 'type', 'title_without_stopwords', \n",
    "                                    'text_without_stopwords', 'hasImage'], errors='ignore')\n",
    "\n",
    "# Ensure 'label' column is valid and convert it to binary values\n",
    "news_data = news_data[news_data['label'].apply(lambda x: isinstance(x, str))]  \n",
    "news_data['label'] = news_data['label'].apply(lambda x: 1 if x.lower() == 'fake' else 0)\n",
    "\n",
    "# Drop missing titles\n",
    "news_data.dropna(subset=['title'], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8438b046",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ========== Tokenization & Sequence Padding ==========\n",
    "MAX_VOCAB_SIZE = 10000  # Max vocabulary size\n",
    "MAX_SEQ_LENGTH = 100     # Max sequence length\n",
    "\n",
    "tokenizer = Tokenizer(num_words=MAX_VOCAB_SIZE, oov_token=\"<OOV>\")\n",
    "tokenizer.fit_on_texts(news_data['title'])\n",
    "\n",
    "# Convert titles to sequences\n",
    "sequences = tokenizer.texts_to_sequences(news_data['title'])\n",
    "padded_sequences = pad_sequences(sequences, maxlen=MAX_SEQ_LENGTH, padding='post', truncating='post')\n",
    "\n",
    "# Convert labels to NumPy array\n",
    "labels = np.array(news_data['label'])\n",
    "\n",
    "# ========== Train-Test Split ==========\n",
    "train_features, test_features, train_labels, test_labels = train_test_split(padded_sequences, labels, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convert to PyTorch tensors\n",
    "train_features_tensor = torch.tensor(train_features, dtype=torch.long)\n",
    "test_features_tensor = torch.tensor(test_features, dtype=torch.long)\n",
    "train_labels_tensor = torch.tensor(train_labels, dtype=torch.long)\n",
    "test_labels_tensor = torch.tensor(test_labels, dtype=torch.long)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1e48acca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LSTMFakeNewsClassifier(\n",
      "  (embedding): Embedding(5943, 128, padding_idx=0)\n",
      "  (lstm): LSTM(128, 128, num_layers=2, batch_first=True)\n",
      "  (fc): Linear(in_features=128, out_features=2, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# ========== Create PyTorch Dataset ==========\n",
    "class FakeNewsDataset(Dataset):\n",
    "    def __init__(self, features, labels):\n",
    "        self.features = features\n",
    "        self.labels = labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.labels)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        return self.features[idx], self.labels[idx]\n",
    "\n",
    "# Data Loaders\n",
    "batch_size = 32\n",
    "train_dataset = FakeNewsDataset(train_features_tensor, train_labels_tensor)\n",
    "test_dataset = FakeNewsDataset(test_features_tensor, test_labels_tensor)\n",
    "\n",
    "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset, batch_size=batch_size)\n",
    "\n",
    "# ========== Define LSTM Model ==========\n",
    "class LSTMFakeNewsClassifier(nn.Module):\n",
    "    def __init__(self, vocab_size, embedding_dim, hidden_dim, num_layers, num_classes):\n",
    "        super(LSTMFakeNewsClassifier, self).__init__()\n",
    "        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=0)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, num_layers, batch_first=True)\n",
    "        self.fc = nn.Linear(hidden_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.embedding(x)  # Convert token IDs to embeddings\n",
    "        out, _ = self.lstm(x)  # LSTM layer\n",
    "        out = self.fc(out[:, -1, :])  # Take last time step's output\n",
    "        return out\n",
    "\n",
    "# ========== Initialize Model ==========\n",
    "vocab_size = min(len(tokenizer.word_index) + 1, MAX_VOCAB_SIZE)  # Ensure vocab size does not exceed limit\n",
    "embedding_dim = 128\n",
    "hidden_dim = 128\n",
    "num_layers = 2\n",
    "num_classes = 2  # Real vs Fake\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = LSTMFakeNewsClassifier(vocab_size, embedding_dim, hidden_dim, num_layers, num_classes).to(device)\n",
    "\n",
    "# Print model summary\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7270b2f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:02<00:00, 19.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Loss: 0.6715224508969289\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:02<00:00, 19.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/5], Loss: 0.668979214047486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:02<00:00, 19.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/5], Loss: 0.6669659254685888\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:02<00:00, 18.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [4/5], Loss: 0.6682211576767687\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████████████████████████████████████████████| 53/53 [00:02<00:00, 19.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [5/5], Loss: 0.6673027232008161\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# ========== Training Setup ==========\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-3)\n",
    "\n",
    "# ========== Training Loop ==========\n",
    "num_epochs = 5\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    for batch_features, batch_labels in tqdm(train_dataloader):\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_features)\n",
    "        loss = criterion(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {running_loss/len(train_dataloader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d64c26c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model saved as fake_news_newsarticle_lstm.pth\n",
      "Accuracy: 0.630071599045346\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "        Real       0.00      0.00      0.00       155\n",
      "        Fake       0.63      1.00      0.77       264\n",
      "\n",
      "    accuracy                           0.63       419\n",
      "   macro avg       0.32      0.50      0.39       419\n",
      "weighted avg       0.40      0.63      0.49       419\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jun_k\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jun_k\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\jun_k\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ========== Evaluation ==========\n",
    "model.eval()\n",
    "all_preds = []\n",
    "all_labels = []\n",
    "with torch.no_grad():\n",
    "    for batch_features, batch_labels in test_dataloader:\n",
    "        batch_features, batch_labels = batch_features.to(device), batch_labels.to(device)\n",
    "        outputs = model(batch_features)\n",
    "        preds = torch.argmax(outputs, dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "# ========== Save Model ==========\n",
    "torch.save(model.state_dict(), \"fake_news_newsarticle_lstm.pth\")\n",
    "print(\"Model saved as fake_news_newsarticle_lstm.pth\")\n",
    "\n",
    "# ========== Evaluation Metrics ==========\n",
    "accuracy = accuracy_score(all_labels, all_preds)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "\n",
    "print(classification_report(all_labels, all_preds, target_names=['Real', 'Fake']))\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "conf_matrix = confusion_matrix(all_labels, all_preds)\n",
    "disp = ConfusionMatrixDisplay(conf_matrix, display_labels=['Real', 'Fake'])\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2be9f34f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Corrected LSTM input shape\n",
    "# Used TF-IDF embeddings instead of BoW\n",
    "# Applied Softmax activation in LSTM model\n",
    "# Added validation set\n",
    "# Saved vectorizer & scaler for inference"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
